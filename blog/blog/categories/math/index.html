<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: math | /usr/sbin/blog]]></title>
  <link href="http://usrsb.in/blog/" rel="self"/>
  <link href="http://usrsb.in/blog/"/>
  <updated>2012-05-20T09:17:33-06:00</updated>
  <id>http://usrsb.in/blog/</id>
  <author>
    <name><![CDATA[Alex Beal]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
    <entry>
      




<title type="html"><![CDATA[Did the Boulder PD Reduce Traffic Accidents?]]></title>
<link href="http://usrsb.in/blog/blog/2012/05/20/did-the-boulder-pd-reduce-traffic-accidents/"/>
<updated>2012-05-20T09:00:00-06:00</updated>
<id>http://usrsb.in/blog/blog/2012/05/20/did-the-boulder-pd-reduce-traffic-accidents</id>

      <content type="html"><![CDATA[<p>There's an article I came across a couple of years ago, which I filed away in the back of my brain, concerning the number of traffic accidents in Boulder. The police department increased enforcement at several intersections, and they were optimistic about the results. At all of the intersections, the number of accidents had dropped compared to the number of accidents in the year before.</p>

<p><blockquote><p>The police department's traffic unit decided early last year to step up enforcement around three intersections that consistently rank among the top accident locations in the city...That meant placing more officers in marked cars at the intersection...Compared with 2008, last year saw 14 fewer accidents at those intersections, an 11 percent decrease.</p><footer><strong>The Daily Camera</strong> <cite><a href='http://www.dailycamera.com/ci_14456899'>www.dailycamera.com/ci_14456899/&hellip;</a></cite></footer></blockquote></p>

<p>The box to the left of the article presents the data, which I've reproduced below:</p>

<p>```
Accident data
Intersection            2008    2009</p>

<p>28th and Arapahoe       52      46</p>

<p>30th and Arapahoe       39      33</p>

<p>Foothills and Arapahoe  35      33</p>

<p>Citywide                3,242   3,405</p>

<p>Source: Boulder Police Department
```</p>

<p>As you may have guessed, I was quite skeptical of this article. Just because a random variable varies from experiment to experiment, doesn't mean the variation is anything but coincidence. I just flipped a coin 4 times. The first two times it was heads, and the second two, it was first heads and then tails. That, of course, doesn't mean the coin suddenly became less lucky. So, the question I want to answer in this post is: <em>Is the Boulder PD justified in thinking that they've decreased the number of traffic accidents at these three intersections?</em></p>

<p>The way I'm going to answer this question is to first model these accidents with a probability distribution, and then use this to find the probability that the decrease in accidents could have been due to random variation. The distribution I'm going to use is a really interesting one called the Poisson distribution. This distribution is great for modeling events that happen very rarely, such as shark attacks and traffic accidents. Many people drive every day, but very few (relatively speaking) are involved in an accident. Further, this distribution has one parameter, λ, and both its variance and expected value are equal to it.</p>

<p><img src="http://media.usrsb.in/traffic-poisson/expected-var.png" title="Expected Value and Variance of the Poisson Distribution" ></p>

<p>The issue, of course, is that we don't know the expected value or variance of traffic accidents at these intersections. We can, though, make a charitable assumption. In the interests of some fun mathematics, let's assume that 2008 was an incredibly average year, and that the number of accidents that occurred that year is exactly the expected value. Since the variance is equal to the expected value, we can, for example, say that the variance is 52 for 28th and Arapahoe.</p>

<p>Now that we know the variance and expected value, we can calculate the <em>z-score</em> of the decrease in accidents. This will tell us the probability that the random variable (in this case, the number of accidents at 28th and Arapahoe) could, by mere chance, decrease by 6 to 46. But wait a minute. z-scores only pertain to normal distributions, and we're using the Poisson distribution. This is ok, though. Since λ is large (λ > 25) it can be approximated with the normal distribution.<sup>1</sup> So, let's calculate the z-score:</p>

<p><img src="http://media.usrsb.in/traffic-poisson/z-val.png" title="z-value of the Normal Distribution" ></p>

<p><img src="http://media.usrsb.in/traffic-poisson/z-val-calc.png" title="z-value of the reduction = 0.832" ></p>

<p>We now know that a decrease of 6 accidents from 52 falls at exactly -0.832 standard deviations from the mean. From this, we can tell that <a href="http://www.wolframalpha.com/input/?i=z-score+-0.832">the chance that the number of accidents in a given year would vary between 46 and 58 (±6 from the mean of 52) is 60%,</a> and the chance that the number of accidents would be something less than or equal to 46 is 20%. So, it seems quite likely that this variation was just random coincidence. The Boulder PD is probably being a bit too optimistic in thinking that it's their additional enforcement that decreased the number of traffic accidents at 28th and Arapahoe. Now, what about the other intersections? I've repeated this calculation for the other three statistics below:</p>

<p>```
Accident data
Intersection            2008    2009    z-value     P(z &lt; z-value) (left tailed p-value)</p>

<p>28th and Arapahoe       52      46      -0.832      0.202</p>

<p>30th and Arapahoe       39      33      -0.971      0.1683</p>

<p>Foothills and Arapahoe  35      33      -0.334      0.369</p>

<p>Citywide                3,242   3,405    2.862      0.0021 (right tailed)
```</p>

<p>The decrease at 30th and Arapahoe is slightly more significant, but still has a 17% chance of being due to randomness. Foothills and Arapahoe fairs the worst of the three, with a whopping 37% chance of being random. Ironically, it is the citywide <em>increase</em> in accidents that is the most significant result. There's only a 0.2% chance that the number of accidents would randomly increase by at least 163! This is statistically significant, and it's plausible that this variation isn't due to random chance. Perhaps the Boulder PD spent too much time at these intersections at a cost to all of the other intersections in the city!</p>

<p>In any case, this analysis is, of course, far from perfect. The assumption I made concerning the expected value may very well have been wrong. Perhaps both 2008 and 2009 were anomalous years, and the expected value is actually much different. I will also grant that it is interesting that the citywide total went up, while these three intersections all went down, but I'm also not sure how much cherry picking they did. Really, the point of this post was to showcase some interesting mathematics, and show how far a little algebra can go. With only a little more data, I think this sort of analysis would have some interesting results. Hopefully someone at Boulder PD is listening. I wonder how much more money they threw at this enforcement campaign without really having any good data on its efficacy.</p>

<h3>Notes</h3>

<ol>
<li>Tijms, Henk. Understanding Probability: Chance Rules in Everyday Life. 2nd ed. New York: Cambridge University Press, 2010. 169. Print.</li>
</ol>


<p><a rel="bookmark" href="http://usrsb.in/blog/blog/2012/05/20/did-the-boulder-pd-reduce-traffic-accidents/">&infin; Permalink</a></p>

]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Search Algorithms: Finding a Bad Coin (Part II)]]></title>
<link href="http://usrsb.in/blog/blog/2011/08/18/search-algorithms-finding-a-bad-coin-part-ii/"/>
<updated>2011-08-18T13:24:00-06:00</updated>
<id>http://usrsb.in/blog/blog/2011/08/18/search-algorithms-finding-a-bad-coin-part-ii</id>

      <content type="html"><![CDATA[<p>In the last post, I discussed a problem about finding the bad coin in a set of 8 coins. Here, I'll do some mathematical analysis of the different algorithms, and talk about the number of steps it takes to search through n coins using each algorithm.</p>

<h2>The Simplest Algorithm</h2>

<p>The first algorithm was the simplest, and consisted of weighing pairs of coins. We begin analyzing this algorithm by first noticing two things: (1) It could take anywhere between 1 and 4 trials to search through the 8 coins. (2) Each of these scenarios is equally likely. There's a 1 in 4 possibility that it will be found on the first trial. Ditto for the second, third, and fourth trial. With these two pieces of information, we can calculate the average number of steps it takes to search through 8 coins. This is done by multiplying each outcome (1, 2, 3, or 4 trials) with its probability (1 in 4) and summing the values. The expected value, or average number of steps for 8 coins, is therefore 2.5.</p>

<p><img src="http://media.usrsb.in/bad-coin/avg-trials.png" alt="average trials" /></p>

<p>Another way of thinking about this goes as follows: Half the time you'll find the coin on or before 2 trials, and half the time you'll find the coin on or after 3 trials. Therefore, the average number of trials is 2.5.</p>

<p>That's simple enough, but can this be generalized? Yes. For n coins, the following sum represents the average number of trials:</p>

<p><img src="http://media.usrsb.in/bad-coin/avgstepssimple.png" alt="average trials general" /></p>

<p>If you're skeptical, try out the sum for 8 coins and verify that it produces the same equation as above. The sum simply multiplies each possible outcome (1, 2, 3, or 4 trials) by one over the total number of possible outcomes (1/4). Note that n must be an even number. If it's not, then round up to the nearest even number.
So, what are the takeaway points?</p>

<ol>
<li>The average number of trials for n coins is proportional to n.</li>
<li>The number of trials isn't fixed. Half the time it will take less than or equal to n/2 trials, and half the time it will take more.</li>
<li>One out of every n/2 times, it will take only 1 trial.</li>
</ol>


<p>The upshot is that the algorithm isn't horrible for a small number of coins, but once n starts to get big, so does the number of steps required. In fact, for 8 coins, this algorithm is slightly better, on average, than the binary search, which always takes exactly 3 steps, but it's also slightly worse than the ternary search, which always takes 2 steps. As I'll show, this doesn't hold when the number of coins gets larger.</p>

<h2>The Binary and Ternary Searches</h2>

<p>Calculating the average number of steps for the binary and ternary search is much easier than for the simple algorithm, because the binary and ternary search always take a fixed number of steps, as shown by the decision tree (this isn't true if the tree is unbalanced, or if n isn't a power of 2 or 3). We can also see that for a decision tree to search through 8 coins, it must have 8 termination points at the bottom of the tree, called "leaves." The number of steps to complete the search is related to this by 2d≥8 for the binary tree and 3d≥8 for the ternary tree, where d is the number of steps or "depth" of the tree (Hein, p. 288). Solving for d we get an expression for the minimum number of steps, where n is the number of coins and b is 2 for a binary tree and 3 for a ternary tree:</p>

<p><img src="http://media.usrsb.in/bad-coin/treesteps.png" alt="Minimum steps to find coin" /></p>

<p>The brackets are the ceiling operator, which rounds the number up, because a tree's depth must be an integer.</p>

<p>Hein takes this a step further and proves that the ternary decision tree is the optimal decision tree (p. 288). If there are 8 coins, there must be 8 leaves on the tree. The minimum depth for a tree with 8 leaves is 2. The tree in the last post has a depth of 2, and therefore must be an optimal tree (among others).</p>

<p>The takeaway points here are:</p>

<ol>
<li>The ternary and binary searches take a fixed number of steps (for a balanced tree where n is a power of 2 or 3)</li>
<li>The number of steps for n coins is proportional to logb(n).</li>
<li>The ternary and binary searches scale much better than the simple algorithm. See the table below:</li>
</ol>


<table>
<tr><td>n</td><td>Simple Algorithm</td><td>Binary</td><td>Ternary</td></tr>
<tr><td>8</td><td>2.5</td><td>3</td><td>2</td></tr>
<tr><td>128</td><td>32.5</td><td>7</td><td>5</td></tr>
<tr><td>1024</td><td>256.5</td><td>10</td><td>7</td></tr>
<tr><td>1,048,576</td><td>262,144.5</td><td>20</td><td>13</td></tr>
</table>


<p>As Jon Bentley points out in <a href="http://www.amazon.com/Programming-Pearls-2nd-Jon-Bentley/dp/0201657880">Programming Pearls</a> [Amazon.com], because the ternary search scales so much better, there's some sufficiently large value of n, at which a pocket calculator running the ternary search will outpace a supercomputer running the simple algorithm.</p>

<p><a rel="bookmark" href="http://usrsb.in/blog/blog/2011/08/18/search-algorithms-finding-a-bad-coin-part-ii/">&infin; Permalink</a></p>

]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[The Surface Area of a Sphere Between Parallel Planes]]></title>
<link href="http://usrsb.in/blog/blog/2011/08/11/the-surface-area-of-a-sphere-between-parallel-planes/"/>
<updated>2011-08-11T15:49:00-06:00</updated>
<id>http://usrsb.in/blog/blog/2011/08/11/the-surface-area-of-a-sphere-between-parallel-planes</id>

      <content type="html"><![CDATA[<p>Here's a math problem that surprised me: Imagine a sphere of diameter <em>d</em> intersected by two parallel planes a distance <em>h</em> apart. What do you think the surface area of the section of the sphere between the planes is? You're first thought might be that there's not enough information. The area will depend upon what part of the sphere the planes intersect. If the planes cut out the middle third of the sphere, that will be a different surface area compared to if the planes cut out the left third or the right third.</p>

<p>That was my first thought, at least, and, as it turns out, it's wrong. <strong>The area only depends on the distance between the planes, and the diameter of the sphere. It doesn't matter where these planes are in relation to the sphere.</strong> As long as they both intersect the sphere, the surface area will equal <em>πdh</em>, where d is the diameter and <em>h</em> is the distance between the planes. Don't believe me? Here's the math to prove it:</p>

<p>First we begin with the formula for the surface area of a function rotated around the x axis from <em>a</em> to <em>b</em>. If you want an explanation of this equation, the section of my textbook that covers this is actually <a href="http://www.stewartcalculus.com/data/ESSENTIAL%20CALCULUS/upfiles/topics/ess_at_06_asr_stu.pdf">posted online [PDF]</a> by the publishers (also note that this is problem 32 from that chapter).</p>

<p><img src="http://media.usrsb.in/sa-sphere/1.png" alt="Suface Area Formula" /></p>

<p>Since we are finding the surface area of a sphere, we need the function for a circle, which we will rotate around the x axis, thus producing our sphere. If we can remember back to high school geometry, we'll know that the equation for a sphere is <em>x2+y2=r2</em>. We now solve for <em>y</em>, and plug it in for <em>f(x)</em>, and also find the derivative of <em>f(x)</em> and plug it in for <em>f'(x)</em>:</p>

<p><img src="http://media.usrsb.in/sa-sphere/2.png" alt="title" /></p>

<p>We now simplify the integral:</p>

<p><img src="http://media.usrsb.in/sa-sphere/3.png" alt="title" /></p>

<p><em>f(x)</em> is moved into the square root:</p>

<p><img src="http://media.usrsb.in/sa-sphere/4.png" alt="title" /></p>

<p>We distribute:</p>

<p><img src="http://media.usrsb.in/sa-sphere/5.png" alt="title" /></p>

<p>More simplification:</p>

<p><img src="http://media.usrsb.in/sa-sphere/6.png" alt="title" /></p>

<p><img src="http://media.usrsb.in/sa-sphere/7.png" alt="title" /></p>

<p>We now integrate:</p>

<p><img src="http://media.usrsb.in/sa-sphere/8.png" alt="title" /></p>

<p><img src="http://media.usrsb.in/sa-sphere/9.png" alt="title" /></p>

<p><img src="http://media.usrsb.in/sa-sphere/10.png" alt="title" /></p>

<p><em>b-a</em> is simply the distance between the two planes, which we call <em>h</em>:</p>

<p><img src="http://media.usrsb.in/sa-sphere/11.png" alt="title" /></p>

<p>2r is the diameter of the sphere, which we call d:</p>

<p><img src="http://media.usrsb.in/sa-sphere/12.png" alt="title" /></p>

<p>There you have it. The surface area of a sphere between two parallel planes is equal to <em>πdh</em>. It doesn't matter where these planes are in relation to the sphere. All that matters is that both planes intersect the sphere. Cool, huh? No? Ok, fine. Well, I thought it was interesting.</p>

<p><a rel="bookmark" href="http://usrsb.in/blog/blog/2011/08/11/the-surface-area-of-a-sphere-between-parallel-planes/">&infin; Permalink</a></p>

]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Fibonacci Sequence, Part II]]></title>
<link href="http://usrsb.in/blog/blog/2011/08/03/fibonacci-sequence-part-ii/"/>
<updated>2011-08-03T16:49:00-06:00</updated>
<id>http://usrsb.in/blog/blog/2011/08/03/fibonacci-sequence-part-ii</id>

      <content type="html"><![CDATA[<p>The matrix equation in the last post can actually be whittled down a bit further to produce another equation that, in some ways, is easier to work with. The result is as follows:</p>

<p><img src="http://media.usrsb.in/fib2/fib.png" alt="fib" /></p>

<p>F<sub>k</sub> is, of course, the k<sup>th</sup> Fibonacci number. Now, before I go on, I want to point out that I stumbled upon these two equations and the proofs for these equations in <a href="http://www-math.mit.edu/~gs/">Gilbert Strang's</a> excellent <a href="http://www.amazon.com/Linear-Algebra-Applications-Gilbert-Strang/dp/0030105676/ref=sr_1_2?s=books&amp;ie=UTF8&amp;qid=1312385275&amp;sr=1-2">Linear Algebra and Its Applications</a>. All credit goes to him for coming up with this, and I recommend his book for an even more in depth explanation.</p>

<p>Anyway, back to the equation, which I found interesting for a few reasons:</p>

<ol>
<li>This equation allows you to easily find the kth term using only a pocket calculator. The last equation requires something that can deal with matrices.</li>
<li>This also makes it easier to use in programming applications. There's no need to write functions or import libraries to deal with matrices. It's also probably faster than writing some sort of recursive function to compute the kth Fibonacci number.</li>
<li>As Strang points out, that equation, amazingly, produces an integer, despite all the fractions and square roots.</li>
<li>We can simplify that equation further for a very good approximation (so good that it's not really an approximation).</li>
</ol>


<p>To see how we get that equation from the equation in the last post, let's begin with the way Mr. Strang has it written in his book (it's the same as mine, but flipped upside down).</p>

<p><img src="http://media.usrsb.in/fib2/fibmat.png" alt="title" /></p>

<p>Where F<sub>0</sub>=0, F<sub>1</sub>=1, F<sub>2</sub>=1, etc. Let's now make some substitutions:</p>

<p><img src="http://media.usrsb.in/fib2/subs.png" alt="title" /></p>

<p>We now have:</p>

<p><img src="http://media.usrsb.in/fib2/matform.png" alt="title" /></p>

<p>This hasn't changed the content of the equation at all. We've just substituted in new symbols to represent the different terms.</p>

<p>The next step is to diagonalize the matrix A. Remember that diagonalizing A produces A = SΛS<sup>-1</sup> where S contains A's eigenvectors and Λ contains A's eigenvalues. Substituting A = SΛS<sup>-1</sup> into the previous equation yields:</p>

<p><img src="http://media.usrsb.in/fib2/diag.png" alt="title" /></p>

<p>Notice how everything but the first and last S and S<sup>-1</sup> cancel, giving the final form: SΛ<sup>k</sup>S<sup>-1</sup>u<sub>0</sub>. This is important, because Λ is a diagonal matrix, making Λ<sup>k</sup> very simple:</p>

<p><img src="http://media.usrsb.in/fib2/lampow.png" alt="title" /></p>

<p>λ<sub>1</sub> and λ<sub>2</sub> are, of course, the eigenvalues of A. Let's now make one last substitution and put all this diagonalization stuff together. First we define c as</p>

<p><img src="http://media.usrsb.in/fib2/csub.png" alt="title" /></p>

<p>Then we substitute it into the equation:</p>

<p><img src="http://media.usrsb.in/fib2/diag2.png" alt="title" /></p>

<p>That might need some explaining. The first bit is simply the equation with c substituted in. Following that, the first matrix is S, but written to show that it contains x<sub>1</sub> and x<sub>2</sub>, which are the eigenvectors of A placed vertically in the two columns. The middle matrix is Λ<sup>k</sup> and the last is simply the matrix c. Finally, the matrices are multiplied out, yielding the final c<sub>1</sub>λ<sup>k</sup><sub>1</sub>x<sub>1</sub>+c<sub>2</sub>λ<sup>k</sup><sub>2</sub>x<sub>2</sub></p>

<p>The final steps are simply to compute c, and A's eigenvalues and eigenvectors. I'll spare you the tedious algebra and simply tell you that:</p>

<p><img src="http://media.usrsb.in/fib2/eigenvals.png" alt="title" /></p>

<p><img src="http://media.usrsb.in/fib2/eigenvec.png" alt="title" /></p>

<p>This can be computed the standard way, by solving: det(A-λI)=0.</p>

<p>All the variables are then plugged into the equation for u<sub>k</sub>.</p>

<p><img src="http://media.usrsb.in/fib2/almost-there.png" alt="title" /></p>

<p>We want F<sub>k</sub>, so we multiply, factor, and take the bottom row, giving the equation we want:</p>

<p><img src="http://media.usrsb.in/fib2/approx.png" alt="title" /></p>

<p>That's the full equation, but now notice that the second term is always less than 1/2. This mean we can simply drop it, yielding:</p>

<p>In fact, since the second term is always less than 1/2 and the full equation always gives us an integer, we can take this a step further: <strong>Rounding the approximation to the nearest integer will always give you the exact value for F<sub>k</sub>.</strong> Cool.</p>

<p><a rel="bookmark" href="http://usrsb.in/blog/blog/2011/08/03/fibonacci-sequence-part-ii/">&infin; Permalink</a></p>

]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Using Matrices to Generate the Fibonacci Sequence]]></title>
<link href="http://usrsb.in/blog/blog/2011/04/10/using-matrices-to-generate-the-fibonacci-sequence/"/>
<updated>2011-04-10T12:47:00-06:00</updated>
<id>http://usrsb.in/blog/blog/2011/04/10/using-matrices-to-generate-the-fibonacci-sequence</id>

      <content type="html"><![CDATA[<p>Here's a fun little matrix:</p>

<p><img src="http://media.usrsb.in/fib-mat/equation.png" alt="Fib Matrix" /></p>

<p>That generates the a<sub>n</sub> and a<sub>n+1</sub> terms of the Fibonacci sequence.<sup>1</sup> To see why, let's look at a recursive definition of the Fibonacci sequence.</p>

<p><img src="http://media.usrsb.in/fib-mat/1.png" alt="Fib Def" /></p>

<p><img src="http://media.usrsb.in/fib-mat/2.png" alt="Fib Def" /></p>

<p>That's easy enough to understand. The first and second terms are both 1, and the next term is the sum of the last term plus the current term. To see how this relates to the matrix above, we must turn this into a matrix equation. The trick here is to have a good understanding of matrix multiplication. If you need a refresher, <a href="http://www.mathsisfun.com/algebra/matrix-multiplying.html">here's a site</a> with a tutorial. Let's look at an example of a 2x2 matrix multiplied by a 2x1 (even if you have a good understanding of matrix multiplication, hang tight, this is going somewhere).</p>

<p><img src="http://media.usrsb.in/fib-mat/3.png" alt="title" /></p>

<p>Now let's make some substitutions and multiply it out:</p>

<p><img src="http://media.usrsb.in/fib-mat/7.png" alt="title" /></p>

<p>As you can see, the effect of multiplying the b matrix by the Fibonacci matrix is that it moves the b<sub>1,2</sub> position to the b<sub>1,1</sub> position, and the b<sub>1,2</sub> gets filled with the sum of b<sub>1,1</sub> and b<sub>1,2</sub>. Let's now substitute the b's for a<sub>n-1</sub> and a<sub>n</sub>:</p>

<p><img src="http://media.usrsb.in/fib-mat/8.png" alt="title" /></p>

<p>Does the resultant matrix look familiar? If you look above, you'll see that it's the same as our recursive definition of the Fibonacci sequence! The top row is equal to the current number in the sequence (a<sub>n</sub>) and the bottom row is equal to the next number in the sequence (a<sub>n-1</sub> + a<sub>n</sub> = a<sub>n+1</sub>). Continuing to multiply the resultant matrix by the Fibonacci matrix will cause consecutive entries to be produced. Because matrix multiplication is associative, we can move our multiplication to the exponent, and multiply that result by the first two terms in the sequence (0, 1), leading to our initial matrix:</p>

<p><img src="http://media.usrsb.in/fib-mat/equation.png" alt="Fib Matrix" /></p>

<h3>References</h3>

<p>1: Strang, Gilbert. "<a href="http://www.amazon.com/Linear-Algebra-Applications-Gilbert-Strang/dp/0030105676/ref=sr_1_2?s=books&amp;ie=UTF8&amp;qid=1312385275&amp;sr=1-2">Linear Algebra and Its Applications</a>."<p><a rel="bookmark" href="http://usrsb.in/blog/blog/2011/04/10/using-matrices-to-generate-the-fibonacci-sequence/">&infin; Permalink</a></p></p>
]]></content>
    </entry>
  
</feed>

