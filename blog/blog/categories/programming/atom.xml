<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: programming | /usr/sbin/blog]]></title>
  <link href="http://usrsb.in/blog/blog/categories/programming/atom.xml" rel="self"/>
  <link href="http://usrsb.in/blog/"/>
  <updated>2012-03-27T09:22:28-06:00</updated>
  <id>http://usrsb.in/blog/</id>
  <author>
    <name><![CDATA[Alex Beal]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Implementing a Logic Evaluator Without if-expressions or Boolean Operators]]></title>
    <link href="http://usrsb.in/blog/blog/2012/01/28/implementing-a-logic-evaluator-without-if-expressions/"/>
    <updated>2012-01-28T10:19:00-07:00</updated>
    <id>http://usrsb.in/blog/blog/2012/01/28/implementing-a-logic-evaluator-without-if-expressions</id>
    <content type="html"><![CDATA[<p>I've slowly been making my way through <a href="http://www.scala-lang.org/sites/default/files/linuxsoft_archives/docu/files/ScalaOverview.pdf">An Overview of the Scala Programming Language</a> [PDF], and was struck by this interesting implementation of Booleans:</p>

<p>``` scala
abstract class Bool {</p>

<pre><code>def &amp;&amp; (x: =&gt; Bool): Bool
def || (x: =&gt; Bool): Bool
</code></pre>

<p>}
object False extends Bool {</p>

<pre><code>def &amp;&amp; (x: =&gt; Bool): Bool = this
def || (x: =&gt; Bool): Bool = x
</code></pre>

<p>}
object True extends Bool {</p>

<pre><code>def &amp;&amp; (x: =&gt; Bool): Bool = x
def || (x: =&gt; Bool): Bool = this
</code></pre>

<p>}
```</p>

<p>If you're not a Scala programmer, don't let the syntax trip you up. It's pretty straightforward. <code>True</code> and <code>False</code> are singleton objects that inherit from the <code>abstract class Bool</code>. Each object implements the <code>&amp;&amp;</code> (and) and <code>||</code> (or) operators. As you'd expect, they each take a <code>Bool</code> as an argument and return a <code>Bool</code>. When you execute:</p>

<p><code>scala
True &amp;&amp; False
</code></p>

<p>It applies <code>True</code>'s <code>&amp;&amp;</code> method to <code>False</code>, and correctly returns <code>x</code>, which is, in this case, <code>False</code>.</p>

<p>What's so interesting about this is the absence of any if-expressions or built-in boolean operators. To illustrate, a less clever, but more obvious implementation would be as follows:</p>

<p>``` scala
def and(x: Boolean, y: Boolean): Boolean = {</p>

<pre><code>if(x)
    if(y)
        true
    else
        false
else
    false
</code></pre>

<p>}
```</p>

<p>So, if <code>x</code> and <code>y</code> are both <code>true</code>, return <code>true   </code>, otherwise return <code>false</code> (Scala returns the value of the last executed expression). It works, but doesn't win any style points. The nested if-expressions are especially ugly.<sup>1<sup></p>

<p>So, this is a neat way of cutting down on if-expressions. Can it be extended to the other operations? Yes:</p>

<p>``` scala
object True extends Bool {
  def &amp;&amp; (x: => Bool): Bool = x
  def || (x: => Bool): Bool = this
  def unary<em>! : Bool = False
  def xor (x: => Bool): Bool = !x
  def if</em> (x: => Bool): Bool = this
  def iff(x: => Bool): Bool = x
}</p>

<p>object False extends Bool {
  def &amp;&amp; (x: => Bool): Bool = this
  def || (x: => Bool): Bool = x
  def unary<em>! : Bool = True
  def xor (x: => Bool): Bool = x
  def if</em> (x: => Bool): Bool = !this
  def iff(x: => Bool): Bool = !x
}
```</p>

<p>One thing I like about this implementation is the pleasing symmetry between <code>True</code>'s methods and <code>False</code>'s methods. The <code>unary_!</code> (not) method is trivially opposite. <code>True</code> returns <code>False</code> and vice versa, but the symmetry continues throughout <code>xor</code>, <code>if_</code>, and <code>iff</code>. For example, <code>False</code>'s <code>xor</code> returns its parameter, while <code>True</code>'s <code>xor</code> returns the opposite of its parameter. <code>False xor True</code> returns <code>True</code>, whereas <code>True xor True</code> returns <code>False</code>. I'll leave verifying the rest of these rules as an exercise to the reader.<sup>2</sup></p>

<p>It's also interesting to compare this to the <a href="http://en.wikipedia.org/wiki/State_pattern">State Pattern</a>, where a state machine is simulated through the use of objects that implement a common interface. Each state is an object, and transitioning between states is as easy as switching between the different objects. Without this pattern, the alternative would be a complex set of if-expressions dictating what you're allowed to do in a certain state, and which states you can switch to given your current state. The State Pattern essentially hides all this behind polymorphism, similar to what's happening in the logic evaluator.</p>

<h2>Notes</h2>

<ol>
<li>You can cut it down to one if-expression if you're on your toes.</li>
<li>Note that <code>if_</code> is backwards. <code>True if_ False</code> is the same as <code>False -&gt; True</code>, because that's closer to the English.</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Picking Random Items: Take Two (Hacking Python's Generators)]]></title>
    <link href="http://usrsb.in/blog/blog/2012/01/14/picking-random-items-take-2/"/>
    <updated>2012-01-14T10:29:00-07:00</updated>
    <id>http://usrsb.in/blog/blog/2012/01/14/picking-random-items-take-2</id>
    <content type="html"><![CDATA[<p>Earlier today I had my mind blown by David Beazley's <a href="http://www.dabeaz.com/generators/">presentation on the power of Python's generators</a>, and it inspired me to write this highly Pythonic version of <a href="/blog/2012/01/11/picking-random-items-from-a-file/">the random word selector</a>, made almost entirely of generators:</p>

<p>``` python
import heapq
import random</p>

<p>lines       = (line for line in open("/usr/share/dict/words"))
word_pairs  = ((random.random(), word) for word in lines)
rand_pairs  = heapq.nlargest(4, word_pairs)</p>

<p>rand_words  = [word for rand, word in rand_pairs]
print rand_words
```</p>

<p>How does this work? First recall that a generator is an object that returns the next item in a sequence every time its <code>next()</code> method is called. There's an example of this on line 4 where a generator named <code>lines</code> is created, which returns the next line of the file every time <code>lines.next()</code> is called. What's so handy about a generator is that it can be automatically consumed by a <code>for</code> loop. That is, put a generator in a <code>for</code> loop, and the loop will automatically call the generator's <code>next()</code> method on every iteration. There's an example of this on line 5 where another generator is created that uses a <code>for</code> loop to consume the <code>lines</code> generator. This outputs a tuple containing a random number and the line returned by <code>lines.next()</code>. So, the result is that each time <code>word_pairs.next()</code> is called, you get the next line of the file paired with a random value (e.g., <code>(0.12345, 'fire\n')</code>). Finally, we use <code>heapq.nlargest(n, iter)</code> to grab the <code>n</code> largest elements from <code>iter</code>. In this case, it repeatedly calls <code>word_pairs.next()</code> and outputs a list of the 4 words with the highest random values.<sup>1</sup> These are our 4 random words. This is all done in around 3 lines (excluding <code>import</code>s and <code>print</code>ing). Wowza.</p>

<p>As Beazley points out, one advantage of this technique is that it resembles the way simple commands are chained together in the shell to create a pipeline. And, just like in the shell, the pipeline is highly modular, so different filters and stages can be easily inserted at different points. Below, I've added two stages to the pipeline that strip the words of their newline characters, and skip words that aren't exactly 13 characters long:</p>

<p>``` python
import heapq
import random</p>

<p>def isValid(word):</p>

<pre><code>return len(word) == 13
</code></pre>

<p>lines       = (line for line in open("/usr/share/dict/words"))
words       = (line.strip() for line in lines)
valid_words = (word for word in words if isValid(word))
word_pairs  = ((random.random(), word) for word in valid_words)
rand_pairs  = heapq.nlargest(4, word_pairs)</p>

<p>rand_words  = [word for rand, word in rand_pairs]
print rand_words
```</p>

<p>The <code>words</code> generator calls <code>strip()</code> on each <code>line</code> which removes the newline character. The <code>valid_words</code> generator only returns words that pass the <code>isValid</code> test. In this case, <code>isValid</code> returns <code>True</code> only if the word is exactly 13 characters long. The end result is 4 random words that are 13 characters long.</p>

<p>One other advantage is that each generator creates its output only when requested. This translates into minimal memory use. The dictionary file being consumed might be gigabytes in size, but only one word will be loaded into memory at a time (excluding buffering done by the <code>file</code> class, etc). It's definitely a neat way of parsing large files.</p>

<p>If you enjoyed this, definitely check out <a href="http://www.dabeaz.com/generators/">Beazley's presentation</a>, and venture further down the rabbit hole.</p>

<h2>Notes</h2>

<ol>
<li>You could even use the built-in function <code>max()</code> if you only need one word.</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Picking Random Items From a File]]></title>
    <link href="http://usrsb.in/blog/blog/2012/01/11/picking-random-items-from-a-file/"/>
    <updated>2012-01-11T10:29:00-07:00</updated>
    <id>http://usrsb.in/blog/blog/2012/01/11/picking-random-items-from-a-file</id>
    <content type="html"><![CDATA[<p>Here's a deceptively simple programming puzzle: Develop an algorithm for randomly selecting <em>n</em> words from a dictionary file. This is essentially the puzzle I had to solve in order to write my <a href="https://github.com/beala/xkcd-password">xkcd-style password generator</a>, which implements the <a href="http://xkcd.com/936/">xkcd password spec</a>.<sup>1</sup></p>

<p>The simplest solution is to parse the dictionary into individual words (easy to do in Python) and put those words into a list. Selecting four random words is then as easy as selecting four random items from the list. This is fast, easy to implement, and simple to understand, but it is also very memory inefficient. I have to load 50,000+ words into memory in order to select four of them.<sup>2</sup> Can we do better? Yes.</p>

<h2>A Memory Efficient Algorithm</h2>

<p>The key insight into developing a better algorithm is realizing that it should be possible to select the words as the dictionary file is being parsed, rather than loading the entire thing into memory. The difficulty is making sure that each word has an equal chance of being chosen, and that at least <em>n</em> words are chosen. If, for example, we simply give each word a 1 in 10 chance of being chosen, we'll end up with way more words than we need (assuming <em>n</em> is small). If we give each a 1 in 50,000 chance, there's the possibility that we won't choose enough words. Bryce Boe has <a href="http://www.bryceboe.com/2009/03/23/random-lines-from-a-file/">a clever solution</a> to this problem where he chooses exactly <em>n</em> words, but the proof that it works is non-trivial, and he doesn't provide it. This is why I came up with my algorithm.</p>

<p>In order to explain my algorithm, it's best to think of it in terms of rolling dice. Consider the following procedure for randomly selecting 4 dice from 10.</p>

<ol>
<li>Roll all 10 dice.</li>
<li>Select the 4 with the highest values.

<ol>
<li>If, suppose, 5 of the dice all end up with a value of 6, randomly choose 4 from those 5 (perhaps by repeating the procedure with those 5).</li>
<li>If, suppose 2 dice get a value of 6, and 3 get a value of 5, select the 2 with the value of 6, and then randomly select 2 of the 3 with a value of 5.</li>
</ol>
</li>
</ol>


<p>How can we adapt this procedure to select random words from a file, rather than dice? Here's how: as we're parsing the dictionary file, we give each word a random value, and then select the <em>n</em> words with the highest values. The issue is, the naive implementation of this procedure doesn't really solve our memory problem. If every word gets a random value, don't we now have to store every word in memory, along with its value? The key here is to observe that only the words with the <em>n</em> highest values need to be kept in memory, and all the others can be immediately discarded. Think about this in terms of the dice example. I want to select 1 die from 10:</p>

<ol>
<li>I roll the first die. I get a value of 1. I keep this die.</li>
<li>I roll the second. I get a value of 3. I keep this die, and discard the other.</li>
<li>I roll the third. I get a value of 3. I keep both dice.</li>
<li>Fourth: I get a value of 6. I keep this die and discard the other 2.</li>
</ol>


<p>By the end of the procedure, I might end up with 3 dice that all got a value of 6. I would then randomly select 1 from those 3.</p>

<p>How can we adapt this procedure for selecting random words? We use a priority queue:</p>

<ol>
<li>Read a word from the dictionary.</li>
<li>Give it a random value.</li>
<li>Insert the value-word pair (as a tuple) into the priority queue.</li>
<li>If the queue has more than <em>n</em> items, pop an item.</li>
<li>Repeat until every word has been read.</li>
</ol>


<p>Remember that popping from a priority queue removes the item with the lowest value. So, we insert a word, and if we have too many words, we pop the one with the lowest value. At the end of this procedure there will be exactly <em>n</em> words in the queue. These are our <em>n</em> random words. Neat.</p>

<p>There is one issue, though. What if two words have the same random value? Well, one solution is to keep both words, and then break the tie at the end like we did in the dice example, but that breaks the elegance of the priority queue implementation. Another is to break ties randomly as soon as they occur, and discard the losing word, but I'm not sure how to do this in a statistically safe way. The easiest solution is to just pray that collisions don't occur. In Python, each call to <code>random()</code> produces 53-bits of precision, so it's very unlikely that two values will collide. If 53-bits isn't enough (yeah right), you can use multiple random numbers. So, rather than a tuple of <code>(value, word)</code>, you can use <code>(value_1, value_2, value_3, word)</code>.<sup>3</sup> Python's priority queue implementation will automatically know how to sort that.</p>

<p>Without further ado, here's the proof of concept:</p>

<p>``` python</p>

<h1>!/usr/bin/python -O</h1>

<p>import random
import heapq</p>

<p>DICT_PATH = "/usr/share/dict/words"
WORD_COUNT = 4</p>

<p>dict_file = open(DICT_PATH)
wordq = []
for line in dict_file:</p>

<pre><code>word = line.strip()
rand_val = random.random()
heapq.heappush(wordq, (rand_val, word) )
if len(wordq) &gt; WORD_COUNT:
    heapq.heappop(wordq)
</code></pre>

<p>print wordq
```</p>

<h2>Endnotes</h2>

<ol>
<li>Summary: a good password is composed of four random words.</li>
<li>A slight improvement on this would be to store only the word's position in the file, rather than the word itself. Then the word could be retrieved by seeking to that position. <a href="http://www.bryceboe.com/2009/03/23/random-lines-from-a-file">http://www.bryceboe.com/2009/03/23/random-lines-from-a-file</a></li>
<li><del>If you're only using one random value, and your dictionary file has 50,000 words, the chance of a collision is 50,000/2<sup>53</sup> , which is roughly 3 in 562 trillion. I'll take those odds.</del> Whoops! This is actually a version of the <a href="http://en.wikipedia.org/wiki/Birthday_problem">birthday problem</a>. The actual probability of a collision is: 1.39e-7. Still quite good.</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Program Analysis For Tail Call Optimization]]></title>
    <link href="http://usrsb.in/blog/blog/2012/01/03/a-program-analysis-for-tail-call-optimization/"/>
    <updated>2012-01-03T12:08:00-07:00</updated>
    <id>http://usrsb.in/blog/blog/2012/01/03/a-program-analysis-for-tail-call-optimization</id>
    <content type="html"><![CDATA[<p>In this post I will outline a method <a href="http://jwepman.com">Josh Wepman</a> and I have developed for detecting tail calls in programs constructed from a subset of Python. Its original purpose was a Python to x86 compiler we worked on together for a compiler construction course at CU.<sup>1</sup> The approach probably isn't new, but it is straightforward and understandable, and might help other novice compiler writers understand a fundamental optimization.</p>

<h2>1. What is a tail call?</h2>

<p>A tail call occurs when a function (the caller) calls another function (the callee) and then immediately returns the callee's value. Here is a simple example where <code>f()</code> is the caller, and <code>g()</code> is the callee:</p>

<p>``` python Example 1.1</p>

<pre><code>def f():
    return g()
</code></pre>

<p>```</p>

<p>So, a function call is in <em>tail call position</em> when its return value is immediately returned. In the above example, it is <code>g()</code> that is in tail call position. Contrast this with the following example, where <code>g()</code> is not in tail call position:</p>

<p>``` python Example 1.2</p>

<pre><code>def f():
    return g() * 2
</code></pre>

<p>```</p>

<p>Here, <code>g()</code> falls within the return statement of <code>f()</code>, but is not in tail call position because <code>g()</code>'s return value is used in the multiplication before it is returned by <code>f()</code>.<sup>2</sup></p>

<p>Also consider the following example where <code>g()</code> is not in tail call position, but could easily be transformed into a program that is:</p>

<p>``` python Example 1.3</p>

<pre><code>def f():
    x = g()
    y = x
    return y
</code></pre>

<p>```</p>

<p>Since the only thing that happens to <code>g()</code>'s value is that it is copied and then returned, the assignments could be removed, and <code>g()</code>'s value could be immediately returned without modifying the semantics of the program. Also notice that <code>x</code> and <code>y</code> are local variables, so it's guaranteed that their values are not used elsewhere in the program, and so they can be safely removed. The semantically equivalent tail calling program would look like the original example (1.1):</p>

<p>``` python Example 1.1</p>

<pre><code>def f():
    return g()
</code></pre>

<p>```</p>

<h2>2. Why bother detecting them?</h2>

<p>Why are tail calls interesting? I want this post to be mainly about the analysis, so I won't delve too deeply into the mechanics of the machine code, but essentially tail calls allow for a compiler optimization where the callee can hand its return value straight to the caller of the caller. This will make more sense when you consider this extended version of example 1.1:</p>

<p>``` python Example 2.1</p>

<pre><code>def g():
    return 1

def f():
    return g()

print f()
</code></pre>

<p>```</p>

<p>Here, <code>g()</code> will return 1 to <code>f()</code> and <code>f()</code> will return 1 to <code>print</code>, but, since all <code>f()</code> does is immediately return <code>g()</code>'s value to <code>print</code>, why not skip that step entirely? That is, why not simply have <code>g()</code> give its return value directly to <code>print</code>? That's how tail call optimization works. In the optimized version, <code>g()</code> returns its value directly to <code>print</code> rather than forcing <code>f()</code> to be the middleman. This is implemented on the machine code level by having the call to <code>g()</code> reuse <code>f()</code>'s stack frame. The result is that when <code>g()</code> returns, it hands its value directly to <code>print</code>.<sup>3</sup> The advantage is that since each call doesn't result in the allocation of a new stack frame, the compiled code will be slightly faster, and the recursion depth will be practically unlimited (or at least not limited by the size of the call stack).</p>

<p>Notice, though, that the actual optimization occurs at the machine code level, in the instruction selection phase of the compiler, which isn't the subject of this post. Instead, the subject is detecting when this optimization can be performed, and, additionally, transforming programs into ones that are eligible for this optimization. More on that in the next section.</p>

<h2>3. Goals of the Analysis</h2>

<p>One of the design goals of the analysis is for it to detect both of the situations outlined in section 1. That is, it should:</p>

<ol>
<li>Detect obvious cases of tail calls, where a function call is directly nested within a <code>return</code> statement and</li>
<li>Detect less obvious cases where a program isn't tail calling, but could be transformed into one that is.</li>
</ol>


<p>To elaborate on the second goal, <em>we want to detect instances where a return value is assigned to a variable, copied through a series of assignments, and then immediately returned without any intervening code.</em> This situation occurs in example 1.3, and is the reason it could be transformed into a tail calling program. Here is another example:</p>

<p>``` python Example 3.1</p>

<pre><code>def f():
    if input():
        x = g()
    else:
        x = 1
    return x
</code></pre>

<p>```</p>

<p>If <code>input()</code> evaluates to true, then the value of <code>g()</code> gets assigned to <code>x</code>, and is immediately returned. Transforming this into a semantically equivalent tail calling program is as simple as pushing the <code>return</code> statement up into the <code>if</code> branch:</p>

<p>``` python Example 3.2</p>

<pre><code>def f():
    if input():
        return g()
    else:
        x = 1
    return x
</code></pre>

<p>```</p>

<p>Now <code>g()</code> is in tail call position, but the semantics of the program haven't changed.</p>

<p>Contrast that with this example that can't be optimized (at least not by this analysis):</p>

<p>``` python Example 3.3</p>

<pre><code>def f():
    x = g()
    print "About to return"
    return x
</code></pre>

<p>```</p>

<p>This example doesn't meet the last requirement that the copied return value is "immediately returned without any intervening code." Since our transformation pushes the <code>return</code> statement up to the function call to <code>g()</code>, we get the following program:</p>

<p>``` python   Example 3.4</p>

<pre><code>def f():
    return g()
    print "About to return"
</code></pre>

<p>```</p>

<p>Now the <code>print</code> statement is never reached. A more nuanced analysis might handle a case like this, but ours won't.</p>

<h2>4. Complications: The naive analysis, dispatch code, and flattening.</h2>

<p>Now that we understand the parameters of the analysis--what we will detect, and what we won't--how do we implement it? The first requirement is to detect obvious cases where function calls are nested within <code>return</code> statements. This seems simple. Just traverse the AST<sup>4</sup> and look for that precise situation: where function calls are nested within <code>return</code> statements. The trouble with this technique, and the reason that I call it the "naive analysis," is that, through the course of compilation, every function call gets turned into a set of nested <code>if</code> statements. Returning to example 1.1:</p>

<p>``` python Example 1.1</p>

<pre><code>def f():
    return g()
</code></pre>

<p>```</p>

<p>This might get transformed into something like:</p>

<p>``` python Example 4.1</p>

<pre><code>def f():
    if ...:
        tmp0 = g()
    else:
        if ...:
            tmp1 = h()
        else:
            tmp1 = throw_error()
        tmp0 = tmp1
    return tmp0
</code></pre>

<p>```</p>

<p>Why the additional complexity? Remember that Python is a dynamic language. One consequence of this is that at compile time, the compiler doesn't know the type of each variable. Is <code>g</code> an <code>int</code>? A <code>float</code>? A class? In many cases, the program needs this information. In the example above, <code>g()</code> will compile to different code if <code>g</code> is the name of a class, versus if <code>g</code> is the name of a function. Because this can't always be detected at compile time, the executable must be able to detect the types of variables, and be ready for every case.<sup>5</sup> Returning to the example, the first <code>if</code> might be testing if <code>g</code> is the name of a class. If it is, instead of calling a function named <code>g</code>, it needs to execute <code>g</code>'s <code>__init__()</code> method. If <code>g</code> isn't a class, then it needs to make sure <code>g</code> is a function. If it isn't, then the program needs to throw a runtime error. This is one reason why dynamic languages can be slow.</p>

<p>In any case, what matters to us is how this affects our analysis, but thankfully it doesn't. Although our compiler has effectively eliminated instances of "obvious" tail calls, the example above is still eligible for transformation into a program that contains tail calls. Since the return values of the function calls are assigned to temporary variables, then returned, the transformation is the same as in the simpler examples: push the <code>return</code> statement up to the function calls:</p>

<p>``` python Example 4.2</p>

<pre><code>def f():
    if ...:
        return g()
    else:
        if ...:
            return h()
        else:
            return throw_error()
        tmp0 = tmp1
    return tmp0
</code></pre>

<p>```</p>

<p>The <code>return</code> statements have now been pushed up into the branches of the <code>if</code> statement, and <code>g()</code>, <code>h()</code>, and <code>throw_error()</code> are now in tail call position. Nice. Notice that this transformation leaves behind <em>dead code</em>. The assignment <code>tmp0 = tmp1</code> and <code>return tmp0</code> are considered "dead" because they will never be reached. Many compilers have a separate phase that removes the dead code that gets created from optimizations like this, but that's beyond the scope of this article.<sup>6</sup></p>

<p>Aside from the addition of dispatch code, there's another important transformation to the code before it reaches the analysis phase. Happily, this transformation actually make detecting tail calls easier. This transformation is called <em>flattening</em>, which means that deeply nested expressions get broken down into simpler statements. Consider this:</p>

<p>``` python Example 4.3</p>

<pre><code>x = input() + 1 + g()
</code></pre>

<p>```</p>

<p>That would get flattened into:</p>

<p>``` python Example 4.4</p>

<pre><code>tmp0 = input()
tmp1 = tmp0 + 1
tmp2 = g()
tmp3 = tmp1 + tmp2
x = tmp3
</code></pre>

<p>```</p>

<p>Notice that the semantics of the program haven't changed, but the nested expression <code>input() + 1 + g()</code> gets broken down, or flattened, into a simple series of assignments.<sup>7</sup> Although this appears to add additional complexity, it actually reduces the number of possible cases our analysis will encounter, and shrinks the depth of the AST. Notice that the examples above have already been flattened.</p>

<p>So now that we have a fuller description of what we're up against, what does the not-so-naive analysis look like?</p>

<h2>5. The Not-So-Naive Analysis</h2>

<p>The not-so-naive analysis is a <em>flow sensitive static analysis</em>. The analysis follows the control flow of the program and, at each program point, records information about the contents of the variables based on certain rules. A <em>program point</em> is roughly every place in a program where the state of the program could change. In a flattened program, this roughly corresponds to the point before and after every line or statement of code. In the example below, each program point is numbered. The numbers correspond to the order in which each program point will be visited:</p>

<p>``` python Example 5.1</p>

<pre><code>{0}
tmp0 = input()
{1}
if tmp0:
    {2}
    tmp1 = f()
    {3}
else:
    {4}
    tmp1 = g()
    {5}
{6}
return tmp1
</code></pre>

<p>```</p>

<p>So, there is a program point before and after each assignment, and a program point before and after the entire <code>if</code> statement. The order in which the two branches of the <code>if</code> statement are visited doesn't matter, but both branches should be visited before leaving the <code>if</code> statement.</p>

<p>Stepping through the program in this order is easy. Each line of code is an item in a list. Traverse the list in order. If you get to an <code>if</code> statement, do a postorder traversal. First visit the <code>if</code> branch and then the <code>else</code>. Once the value of these branches is determined, the value after the entire <code>if</code> statement can be determined. In other words, in order to determine the value at program point 6, the values at 3 and 5 must be evaluated first.</p>

<p>What do I mean by "the value at program point 6?" As hinted at above, each program point is associated with a set of variables. Roughly, this set corresponds to the set of variables that contain return values. The specifics of how variables get added and removed from the set is the subject of a set of rules. Formally, each rule is a function that takes in the set at a program point (usually the one above the current statement) and the statement itself, and outputs a new set that corresponds to the program point after that statement. So, for example, the value at program point 5 is determined by looking at program point 4 and the statement on line 10 (<code>tmp1 = g()</code>). Because that statement stores a return value to <code>tmp1</code>, <code>tmp1</code> gets added to the set at point 5. This is one of the rules. Below are the rules in full. As a shorthand, the program point before a statement is called R<sub>before</sub> and the point after is called R<sub>after</sub>.</p>

<ol>
<li>If the statement is an assignment between variable <code>v</code> and a function call (<code>v = g()</code>), then <em>R<sub>after</sub> = {v}</em>.</li>
<li>If the statement is an assignment from variable <code>t</code> to variable <code>v</code> (<code>v = t</code>), and <code>t</code> is in R<sub>before</sub>, then <em>R<sub>after</sub> = {v}</em>.</li>
<li>At the start of a program, the beginning of a new code block (e.g. the beginning of a branch in an <code>if</code> statement), or the beginning and end of a new scope <em>R<sub>before</sub> = {}</em>.</li>
<li>If the statement is an <code>if</code> statement, then <em>R<sub>after</sub> = R<sub>after-if</sub> âˆª R<sub>after-else</sub></em>. In other words, it is the union of the R<sub>after</sub>s of each branch.</li>
<li>If the statement is a <code>return</code> statement, and variable <code>v</code> is being returned (<code>return v</code>), and <code>v</code> is in R<sub>before</sub>, then the <code>return</code> statement can be pushed up to wherever <code>v</code>'s value was originally created. In other words, there's some function call above that can be put into tail call position (the function that created the value held by <code>v</code>).</li>
<li>In all other cases, <em>R<sub>after</sub> = {}</em>.</li>
</ol>


<p>Some of these rules are intuitive. Some aren't. I'll go through them one by one and explain them. Keep in mind the goal of the analysis: we're trying to detect when return values are copied through a series of assignments and then returned without any intervening code.</p>

<p>This makes the first rule the most intuitive. If a variable gets assigned a return value, add that variable to the set. This would be the first step in detecting something like example 1.3, reproduced below with the sets at each program point. Notice rule 1 in action on lines 4 and 5:</p>

<p>``` python Example 1.3/5.2
{}
def f():</p>

<pre><code>{}
x = g()
{x}
y = x
{y}
return y
</code></pre>

<p>```</p>

<p>The second rule keeps track of return values that get copied between variables, and is the reason the set contains <code>y</code> after the 6<sup>th</sup> line. The value of <code>x</code> gets copied to <code>y</code>, and <code>x</code> happens to be in R<sub>before</sub>, so, by rule 2, <code>y</code> is now in R<sub>after</sub>.</p>

<p>The third rules initializes the analysis, and starts the program with an empty set. This rule should also be applied to new code blocks. The two branches of an <code>if</code> statement should begin with empty sets as shown below in a new example:</p>

<p>``` python Example 5.3
{}
y = g()
{y}
if input():</p>

<pre><code>{}
y = f()
{y}
</code></pre>

<p>else:</p>

<pre><code>{}
y = h()
{y}
print "Called h()"
{}
</code></pre>

<p>{y}
return y
```</p>

<p>Although <code>y</code> is in the set before the <code>if</code> statement, both branches of the <code>if</code> statement begin with an empty set.</p>

<p>Example 5.3 also demonstrates rule four. The set after an <code>if</code> statement contains the union of the two branches, in this case just <code>y</code>.</p>

<p>The fifth rule comes into play on line 15. <code>y</code> is returned, and it also happens to be in R<sub>before</sub>. This means that the function call that gave <code>y</code> its value can be put in tail call position. This is done by pushing the <code>return</code> statement up to the call to <code>f()</code> on line 6:</p>

<p>``` python Example 5.4
{}
x = g()
{x}
if input():</p>

<pre><code>{}
return f() # Optimized to tail call position.
{y}
</code></pre>

<p>else:</p>

<pre><code>{}
y = h()
{y}
print "Called h()"
{}
</code></pre>

<p>{y}
return y
```</p>

<p>The program has now been transformed into a tail calling program. The analysis has detected that a return value was assigned to a variable, and then returned without any intervening code. Notice, though, that the call to <code>h()</code> on line 10 wasn't optimized. It was almost eligible for transformation, but the intervening <code>print</code> statement on line 12 trigged the last rule, and, correctly, prevented the <code>return</code> statement from being pushed up to the call  to <code>h()</code>. This is the purpose of the last rule--to prevent intervening code from becoming dead code.</p>

<p>There is one last bit of housekeeping. In order for rule 5 to be executed, it needs to know where a variable's value was originally created. Consider, once again, example 1.3:</p>

<p>``` python Example 1.3/5.2
{}
def f():</p>

<pre><code>{}
x = g()
{x}
y = x
{y}
return y
</code></pre>

<p>```</p>

<p>The analysis will detect that <code>y</code> is being returned, and recognize that <code>y</code> is in R<sub>before</sub>. This will trigger rule 5, and the analysis will need to know where <code>y</code>'s value was originally created. How will it determine this? The algorithm is simple:</p>

<ol>
<li>When <code>g()</code> is first assigned to <code>x</code> and <code>x</code> gets added to R<sub>after</sub>, the analysis will record that <code>x</code> is associated with that line (or AST node).</li>
<li>When <code>x</code> gets copied to <code>y</code>, the analysis looks up whichever node/line <code>x</code> was associated with, and then records that <code>y</code> is associated with that same node/line.</li>
<li>When the analysis gets to the last line, it knows that <code>y</code> is associated with line 4 (<code>x = g()</code>), and knows that it can push the <code>return</code> statement up to that position.</li>
</ol>


<p>We are left with the optimized version:</p>

<p>``` python Example 5.5</p>

<pre><code>def f():
    return g()
    # Dead code
    y = x
    return y
</code></pre>

<p>```</p>

<h2>6. Conclusion</h2>

<p>Congratulations if you've gotten this far. We've covered a lot of ground. I've touched on several parts of the compiler, and described, in detail, a program analysis for detecting tail calls. Notice, though, that this analysis only covers a very small subset of Python. The rules assume that all <code>if</code> statements also have an <code>else</code> branch. How could this be fixed? I also haven't addressed other control flow structures. Adding a rule for <code>while</code> loops would be an important addition. All of these issues would be good exercises to think about, and will, perhaps be the subjects of followup posts.</p>

<h2>Footnotes</h2>

<ol>
<li>I'm currently in the early stages of forking the project, which I've redubbed <a href="http://github.com/beala/bullfrog">bullfrog</a>.</li>
<li><a href="http://en.wikipedia.org/wiki/Tail_call#Syntactic_form">http://en.wikipedia.org/wiki/Tail_call#Syntactic_form</a></li>
<li><a href="http://en.wikipedia.org/wiki/Tail_call#In_assembler">http://en.wikipedia.org/wiki/Tail_call#In_assembler</a></li>
<li>AST: Abstract Syntax Tree. A tree representation of the structure (syntax) of a program. <a href="http://en.wikipedia.org/wiki/Abstract_syntax_tree">Wiki</a>.</li>
<li>This is one reason dynamic languages can be slow, but most compilers perform additional optimizations to cut down on so called "dispatch code" by detecting variables types at compile time. This is possible when, for example, an integer is explicitly assigned to a variable: <code>x = 1</code>. In that case, it's guaranteed that <code>x</code> contains an integer.</li>
<li>Dead code elimination. (2011, October 20). In Wikipedia, The Free Encyclopedia. Retrieved 16:56, December 24, 2011, from <a href="http://en.wikipedia.org/w/index.php?title=Dead_code_elimination&amp;oldid=456578651">http://en.wikipedia.org/w/index.php?title=Dead_code_elimination&amp;oldid=456578651</a></li>
<li>At first blush, this doesn't look nested, but it is: <code>x = (((input()) + 1) + g())</code>. The infix notation is deceptive, but, as demonstrated by the parenthesized version, there are actually 2 levels of addition that roughly correspond to the structure of the flattened code.</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Implementing Switches With Dictionaries (Python)]]></title>
    <link href="http://usrsb.in/blog/blog/2011/12/29/implementing-switches-with-dictionaries/"/>
    <updated>2011-12-29T10:55:00-07:00</updated>
    <id>http://usrsb.in/blog/blog/2011/12/29/implementing-switches-with-dictionaries</id>
    <content type="html"><![CDATA[<p>One thing I like about Python is that it lets you do just about anything. Classes can be modified at runtime, lists can contain a mix of types, and functions are first-class. The built in dictionaries are especially powerful. They are fast, and can hash and contain just about any immutable datatype, including functions. This allows for a novel use: fast <code>switch</code> statements. Consider the following bit of C, which adds, subtracts, or multiplies two numbers based on the value of <code>op</code>:</p>

<p>``` c A C Calculator
switch(op) {</p>

<pre><code>case '+':
    c = a + b;
    break;
case '-':
    c = a - b;
    break;
default:
    c = a * b;
    break;
</code></pre>

<p>}
```</p>

<p>This behavior could be duplicated in Python using an <code>if ... elif ... elif ...</code> sequence,<sup>1</sup> or we could use the following dictionary:</p>

<p>``` python A Python Calculator
def add():</p>

<pre><code>return a + b
</code></pre>

<p>def sub():</p>

<pre><code>return a - b
</code></pre>

<p>def mult():</p>

<pre><code>return a * b
</code></pre>

<p>switch_substitute = {</p>

<pre><code>'+' : add,
'-' : sub }
</code></pre>

<p>c = switch_substitute.get(op, mult)()
```</p>

<p>There, the three operations are wrapped in functions, and added as values to the dictionary. The <code>get()</code> method looks for the function associated with the value of <code>op</code> and returns the <code>mult</code> function if the key is not in the dictionary, mimicking the action of the <code>default</code> case.<sup>2</sup> Once one of the functions is retrieved, it's immediately called, and the appropriate value gets assigned to <code>c</code>.</p>

<p>The advantage of this method is that it's fast. Dictionaries are implemented as hash tables, so the lookup happens in constant time.<sup>3</sup> <code>elif</code>s and <code>switch</code>es probably take linear time, but would depend on the implementation.</p>

<p>It's also worth thinking about how something similar could be built using a class and Python's <a href="http://docs.python.org/library/functions.html#getattr">getattr</a> function.</p>

<h2>Footnotes:</h2>

<ol>
<li><a href="http://docs.python.org/tutorial/controlflow.html#if-statements">http://docs.python.org/tutorial/controlflow.html#if-statements</a></li>
<li><a href="http://docs.python.org/library/stdtypes.html#dict.get">http://docs.python.org/library/stdtypes.html#dict.get</a></li>
<li><a href="http://docs.python.org/library/stdtypes.html#mapping-types-dict">http://docs.python.org/library/stdtypes.html#mapping-types-dict</a></li>
</ol>

]]></content>
  </entry>
  
</feed>
